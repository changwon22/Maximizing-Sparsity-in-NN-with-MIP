{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "cbca8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "d351cada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4, 2), y shape: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "# XOR dataset\n",
    "X = np.array([[0., 0.],\n",
    "              [0., 1.],\n",
    "              [1., 0.],\n",
    "              [1., 1.]], dtype=float)\n",
    "y = np.array([[0.], [1.], [1.], [0.]], dtype=float)\n",
    "m, d = X.shape\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "e16074e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=[0. 0.] -> XOR=0.0\n",
      "x=[0. 1.] -> XOR=1.0\n",
      "x=[1. 0.] -> XOR=1.0\n",
      "x=[1. 1.] -> XOR=0.0\n"
     ]
    }
   ],
   "source": [
    "# Single-hidden-layer ReLU network (width=2) that implements XOR exactly.\n",
    "\n",
    "W = np.array([[1, -1],\n",
    "              [-1, 1]], dtype=float)\n",
    "b = np.array([0, 0], dtype=float)\n",
    "v = np.array([1, 1], dtype=float)\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def xor_relu(x):\n",
    "    n= W @ x +b\n",
    "    h1 = relu(n[0])\n",
    "    h2 = relu(n[1])\n",
    "    h=[h1, h2]\n",
    "    y = v @ h\n",
    "    return y\n",
    "\n",
    "for x in X:\n",
    "    y = xor_relu(x)\n",
    "    print(f\"x={x} -> XOR={y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2f5a53",
   "metadata": {},
   "source": [
    "Conventional Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "061b3fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4, 2), y shape: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "# XOR dataset\n",
    "X = np.array([[0., 0.],\n",
    "              [0., 1.],\n",
    "              [1., 0.],\n",
    "              [1., 1.]], dtype=float)\n",
    "y = np.array([[0.], [1.], [1.], [0.]], dtype=float)\n",
    "m, d = X.shape\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "5bb70558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss=0.9195\n",
      "epoch 1000, loss=0.1859\n",
      "epoch 2000, loss=0.1779\n",
      "epoch 3000, loss=0.1759\n",
      "epoch 4000, loss=0.1751\n",
      "epoch 5000, loss=0.1747\n",
      "epoch 6000, loss=0.1743\n",
      "epoch 7000, loss=0.1742\n",
      "epoch 8000, loss=0.1740\n",
      "epoch 9000, loss=0.1739\n",
      "\n",
      "Final predictions:\n",
      "x=[0. 0.], target=0.0, pred=0.500\n",
      "x=[0. 1.], target=1.0, pred=0.999\n",
      "x=[1. 0.], target=1.0, pred=0.999\n",
      "x=[1. 1.], target=0.0, pred=0.001\n",
      "\n",
      "Final parameters:\n",
      "W1 =\n",
      " [[2.246 2.246]\n",
      " [3.659 3.659]]\n",
      "b1 = [-0.022 -3.659]\n",
      "W2 =\n",
      " [[ 3.184]\n",
      " [-5.923]]\n"
     ]
    }
   ],
   "source": [
    "def relu_grad(z):\n",
    "    return (z > 0).astype(float)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "np.random.seed(0)\n",
    "W1 = np.random.randn(2, 2)   # (hidden_dim, input_dim)\n",
    "b1 = np.zeros((2,))          # (hidden_dim,)\n",
    "W2 = np.random.randn(2, 1)   # (hidden_dim, output_dim)\n",
    "\n",
    "lr = 0.1\n",
    "for epoch in range(10000):\n",
    "    # Forward pass\n",
    "    z1 = X @ W1.T + b1      # shape (4,2)\n",
    "    h = relu(z1)            # hidden layer\n",
    "    z2 = h @ W2     # shape (4,1)\n",
    "    y_pred = sigmoid(z2)    # output\n",
    "\n",
    "    # Loss (binary cross-entropy)\n",
    "    eps = 1e-8\n",
    "    loss = -np.mean(y*np.log(y_pred+eps) + (1-y)*np.log(1-y_pred+eps))\n",
    "\n",
    "    # Backprop\n",
    "    dz2 = (y_pred - y) / m   # (4,1)\n",
    "    dW2 = h.T @ dz2\n",
    "\n",
    "    dh = dz2 @ W2.T                   # (4,2)\n",
    "    dz1 = dh * relu_grad(z1)          # (4,2)\n",
    "    dW1 = dz1.T @ X\n",
    "    db1 = np.sum(dz1, axis=0)\n",
    "\n",
    "    # Update\n",
    "    W2 -= lr * dW2\n",
    "    W1 -= lr * dW1\n",
    "    b1 -= lr * db1\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"epoch {epoch}, loss={loss:.4f}\")\n",
    "\n",
    "# Test\n",
    "print(\"\\nFinal predictions:\")\n",
    "for x, y in zip(X, y):\n",
    "    z1 = x @ W1.T + b1\n",
    "    h = relu(z1)\n",
    "    z2 = h @ W2\n",
    "    y_pred = sigmoid(z2)\n",
    "    print(f\"x={x}, target={y[0]}, pred={y_pred[0]:.3f}\")\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "print(\"\\nFinal parameters:\")\n",
    "print(\"W1 =\\n\", W1)\n",
    "print(\"b1 =\", b1)\n",
    "print(\"W2 =\\n\", W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "18adc23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4, 2), y shape: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "# XOR dataset\n",
    "X = np.array([[0., 0.],\n",
    "              [0., 1.],\n",
    "              [1., 0.],\n",
    "              [1., 1.]], dtype=float)\n",
    "y = np.array([[0.], [1.], [1.], [0.]], dtype=float)\n",
    "m, d = X.shape\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "7b4ccc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped with loss=0.3430678091\n",
      "\n",
      "Final parameters:\n",
      "W1 =\n",
      " [[1.687636 1.685144]\n",
      " [2.376624 2.375448]]\n",
      "b1 = [-0.006962 -2.37311 ]\n",
      "W2 =\n",
      " [[ 1.55871 ]\n",
      " [-3.301613]]\n",
      "\n",
      "Predictions:\n",
      "x=[0. 0.], target=0.0, pred_prob=0.686202289, pred=1\n",
      "x=[0. 1.], target=1.0, pred_prob=0.931379771, pred=1\n",
      "x=[1. 0.], target=1.0, pred_prob=0.931379771, pred=1\n",
      "x=[1. 1.], target=0.0, pred_prob=0.068620229, pred=0\n"
     ]
    }
   ],
   "source": [
    "def lrelu(z, a=0.1): return np.where(z > 0, z, a*z)\n",
    "def lrelu_grad(z, a=0.1): return np.where(z > 0, 1.0, a)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "hidden_dim = 2      # wider hidden layer helps when output bias is removed\n",
    "W1 = np.random.randn(hidden_dim, d) * np.sqrt(2.0/d)   # He init for (Leaky)ReLU\n",
    "b1 = np.zeros((hidden_dim,))\n",
    "W2 = np.random.randn(hidden_dim, 1) * 0.1              # small init\n",
    "# NOTE: no b2\n",
    "\n",
    "lr = 0.1\n",
    "max_epochs = 200000\n",
    "tol = 1e-7\n",
    "eps = 1e-12\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    # Forward\n",
    "    z1 = X @ W1.T + b1            # (4, hidden_dim)\n",
    "    h  = lrelu(z1)                # (4, hidden_dim)\n",
    "    z2 = h @ W2                   # (4, 1)   # <-- no output bias\n",
    "    y_pred = sigmoid(z2)\n",
    "\n",
    "    # Loss\n",
    "    loss = -np.mean(y*np.log(y_pred+eps) + (1-y)*np.log(1-y_pred+eps))\n",
    "\n",
    "    # Early stop when microscopic\n",
    "    if loss < tol:\n",
    "        break\n",
    "\n",
    "    # Backprop\n",
    "    dz2 = (y_pred - y) / m                  # (4,1)\n",
    "    dW2 = h.T @ dz2                         # (hidden_dim,1)\n",
    "\n",
    "    dh  = dz2 @ W2.T                        # (4,hidden_dim)\n",
    "    dz1 = dh * lrelu_grad(z1)               # (4,hidden_dim)\n",
    "    dW1 = dz1.T @ X                         # (hidden_dim, d)\n",
    "    db1 = np.sum(dz1, axis=0)               # (hidden_dim,)\n",
    "\n",
    "    # Update\n",
    "    W2 -= lr * dW2\n",
    "    W1 -= lr * dW1\n",
    "    b1 -= lr * db1\n",
    "\n",
    "# Report\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "print(f\"Stopped with loss={loss:.10f}\")\n",
    "print(\"\\nFinal parameters:\")\n",
    "print(\"W1 =\\n\", W1)\n",
    "print(\"b1 =\", b1)\n",
    "print(\"W2 =\\n\", W2)\n",
    "\n",
    "print(\"\\nPredictions:\")\n",
    "for i in range(len(X)):\n",
    "    z1 = X[i] @ W1.T + b1\n",
    "    h  = lrelu(z1)\n",
    "    z2 = h @ W2\n",
    "    p  = sigmoid(z2).item()\n",
    "    print(f\"x={X[i]}, target={y[i,0]:.1f}, pred_prob={p:.9f}, pred={int(p>=0.5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b4e4ac",
   "metadata": {},
   "source": [
    "Gurobipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "c2a70eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "36a272e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (4, 2), y shape: (4, 1)\n"
     ]
    }
   ],
   "source": [
    "# XOR dataset\n",
    "X = np.array([[0., 0.],\n",
    "              [0., 1.],\n",
    "              [1., 0.],\n",
    "              [1., 1.]], dtype=float)\n",
    "y = np.array([[0.], [1.], [1.], [0.]], dtype=float)\n",
    "N, d = X.shape\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "0c0f7998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter NonConvex to value 2\n",
      "Gurobi Optimizer version 12.0.2 build v12.0.2rc0 (mac64[arm] - Darwin 24.5.0 24F74)\n",
      "\n",
      "CPU model: Apple M3\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Non-default parameters:\n",
      "NonConvex  2\n",
      "\n",
      "Optimize a model with 32 rows, 40 columns and 80 nonzeros\n",
      "Model fingerprint: 0x3f1ab52a\n",
      "Model has 8 quadratic constraints\n",
      "Variable types: 28 continuous, 12 integer (12 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+02]\n",
      "  QMatrix range    [1e+00, 1e+00]\n",
      "  QLMatrix range   [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+02]\n",
      "  RHS range        [3e+01, 3e+01]\n",
      "  QRHS range       [1e+00, 1e+00]\n",
      "Presolve removed 2 rows and 2 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 82 rows, 47 columns, 216 nonzeros\n",
      "Presolved model has 12 bilinear constraint(s)\n",
      "\n",
      "Solving non-convex MIQCP\n",
      "\n",
      "Variable types: 35 continuous, 12 integer (12 binary)\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 41 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0   17          -    0.00000      -     -    0s\n",
      "     0     0    0.00000    0   15          -    0.00000      -     -    0s\n",
      "     0     0    0.00000    0    8          -    0.00000      -     -    0s\n",
      "     0     0    0.00000    0    9          -    0.00000      -     -    0s\n",
      "     0     0    0.00000    0    7          -    0.00000      -     -    0s\n",
      "     0     0    0.00000    0    7          -    0.00000      -     -    0s\n",
      "     0     0    0.00000    0    7          -    0.00000      -     -    0s\n",
      "     0     0    0.00000    0    7          -    0.00000      -     -    0s\n",
      "     0     2    0.00000    0    7          -    0.00000      -     -    0s\n",
      "H   32    52                       4.0000000    0.00000   100%   7.6    0s\n",
      " 264721 16590 infeasible   41         4.00000    1.00000  75.0%   8.2    5s\n",
      " 539910  3285 infeasible   31         4.00000    3.00000  25.0%   7.3   10s\n",
      "\n",
      "Cutting planes:\n",
      "  Implied bound: 4\n",
      "  MIR: 4\n",
      "  Flow cover: 4\n",
      "  RLT: 3\n",
      "  Relax-and-lift: 2\n",
      "\n",
      "Explored 572552 nodes (4092827 simplex iterations) in 10.46 seconds (11.06 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 4 4 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.000000000000e+00, best bound 4.000000000000e+00, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "# width of a single hidden layer\n",
    "l1=2\n",
    "M=10000000.0 # minimum Big-M to achieve feasibility (empirically) (0*5)\n",
    "\n",
    "m = gp.Model()\n",
    "\n",
    "m.Params.NonConvex = 2\n",
    "\n",
    "# Bounds\n",
    "Bw = 10.0     # |W_ij| <= Bw\n",
    "Bb = 10.0     # |b_i|  <= Bb\n",
    "Bv = 10.0     # |v_i|  <= Bv\n",
    "\n",
    "Ms = Bw * Bv\n",
    "M = d*Bw + Bb\n",
    "\n",
    "W = m.addVars(l1, d, lb=-Bw, ub=Bw, vtype=GRB.CONTINUOUS, name=\"W\")\n",
    "b = m.addVars(l1,lb=-Bb, ub=Bb, vtype=GRB.CONTINUOUS, name=\"b\")\n",
    "v = m.addVars(l1, lb=-Bv, ub=Bv, vtype=GRB.CONTINUOUS, name=\"v\")\n",
    "\n",
    "p = m.addVars(N, l1, lb=0.0, vtype=GRB.CONTINUOUS, name=\"p\")\n",
    "q = m.addVars(N, l1, lb=0.0, vtype=GRB.CONTINUOUS, name=\"q\")\n",
    "z = m.addVars(N, l1, vtype=GRB.BINARY, name=\"z\")\n",
    "\n",
    "s = m.addVars(l1, d, lb=-Ms, ub=Ms, vtype=GRB.CONTINUOUS, name=\"s\")\n",
    "t = m.addVars(l1, d, vtype=GRB.BINARY, name=\"t\")\n",
    "\n",
    "m.setObjective(gp.quicksum(t[i,j] for i in range(l1) for j in range(d)), GRB.MINIMIZE)\n",
    "\n",
    "for n in range(N):\n",
    "    for i in range(l1):\n",
    "        m.addConstr(\n",
    "            gp.quicksum(W[i,j] * X[n, j] for j in range(d)) + b[i]\n",
    "            == p[n, i] - q[n, i],\n",
    "            name=f\"affine_{n}_{i}\"\n",
    "        )\n",
    "\n",
    "for n in range(N):\n",
    "    for i in range(l1):\n",
    "        m.addConstr(p[n,i] <= M * (1 - z[n,i]), name=f\"pBigM_{n}_{i}\")\n",
    "        m.addConstr(q[n,i] <= M * z[n,i],       name=f\"qBigM_{n}_{i}\")\n",
    "\n",
    "for n in range(N):\n",
    "    m.addConstr(\n",
    "        gp.quicksum(p[n,i] * v[i] for i in range(l1)) == y[n,0],\n",
    "        name=f\"out_{n}\"\n",
    "    )\n",
    "\n",
    "for i in range(l1):\n",
    "    for j in range(d):\n",
    "        m.addConstr(s[i,j] == W[i,j] * v[i],       name=f\"s_def_{i}_{j}\")\n",
    "        m.addConstr( s[i,j] <=  Ms * t[i,j],        name=f\"s_up_{i}_{j}\")\n",
    "        m.addConstr(-s[i,j] <=  Ms * t[i,j],        name=f\"s_lo_{i}_{j}\")\n",
    "\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "5d41965a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value = 4\n",
      "W[0,0] = -0.386436\n",
      "W[0,1] = -0.386436\n",
      "W[1,0] = -6.44507\n",
      "W[1,1] = -6.44507\n",
      "b[0] = 0.772872\n",
      "b[1] = 8.59938\n",
      "v[0] = 5.18628\n",
      "v[1] = -0.466118\n",
      "p[0,0] = 0.772872\n",
      "p[0,1] = 8.59938\n",
      "p[1,0] = 0.386436\n",
      "p[1,1] = 2.15431\n",
      "p[2,0] = 0.386436\n",
      "p[2,1] = 2.15431\n",
      "p[3,0] = 0\n",
      "p[3,1] = 0\n",
      "q[0,0] = 0\n",
      "q[0,1] = 0\n",
      "q[1,0] = 0\n",
      "q[1,1] = 0\n",
      "q[2,0] = 0\n",
      "q[2,1] = 0\n",
      "q[3,0] = 0\n",
      "q[3,1] = 4.29075\n",
      "z[0,0] = 0\n",
      "z[0,1] = 0\n",
      "z[1,0] = 0\n",
      "z[1,1] = 0\n",
      "z[2,0] = 0\n",
      "z[2,1] = 0\n",
      "z[3,0] = 0\n",
      "z[3,1] = 1\n",
      "s[0,0] = -2.00416\n",
      "s[0,1] = -2.00416\n",
      "s[1,0] = 3.00416\n",
      "s[1,1] = 3.00416\n",
      "t[0,0] = 1\n",
      "t[0,1] = 1\n",
      "t[1,0] = 1\n",
      "t[1,1] = 1\n"
     ]
    }
   ],
   "source": [
    "if m.status not in [GRB.OPTIMAL, GRB.SUBOPTIMAL]:\n",
    "    print(f\"Model status: {m.status}\")\n",
    "else:\n",
    "    print(f\"Objective value = {m.objVal:g}\")\n",
    "    for vv in m.getVars():\n",
    "        print(f\"{vv.VarName} = {vv.X:g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "6638f482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =\n",
      " [[-0.386436 -0.386436]\n",
      " [-6.445067 -6.445067]]\n",
      "b = [0.772872 8.59938 ]\n",
      "v = [ 5.186281 -0.466118]\n",
      "p =\n",
      " [[0.772872 8.59938 ]\n",
      " [0.386436 2.154313]\n",
      " [0.386436 2.154313]\n",
      " [0.       0.      ]]\n",
      "q =\n",
      " [[0.       0.      ]\n",
      " [0.       0.      ]\n",
      " [0.       0.      ]\n",
      " [0.       4.290755]]\n",
      "z =\n",
      " [[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]]\n",
      "s =\n",
      " [[-2.004165 -2.004165]\n",
      " [ 3.004165  3.004165]]\n",
      "t =\n",
      " [[1 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "solW = m.getAttr(\"X\", W); solb = m.getAttr(\"X\", b); solv = m.getAttr(\"X\", v)\n",
    "solp = m.getAttr(\"X\", p); solq = m.getAttr(\"X\", q); solz = m.getAttr(\"X\", z)\n",
    "sols = m.getAttr(\"X\", s); solt = m.getAttr(\"X\", t)\n",
    "\n",
    "W_val = np.array([[solW[i,j] for j in range(d)] for i in range(l1)])\n",
    "b_val = np.array([solb[i] for i in range(l1)])\n",
    "v_val = np.array([solv[i] for i in range(l1)])\n",
    "\n",
    "p_val = np.array([[solp[n,i] for i in range(l1)] for n in range(N)])\n",
    "q_val = np.array([[solq[n,i] for i in range(l1)] for n in range(N)])\n",
    "z_val = np.array([[solz[n,i] for i in range(l1)] for n in range(N)], dtype=int)\n",
    "\n",
    "s_val = np.array([[sols[i,j] for j in range(d)] for i in range(l1)])\n",
    "t_val = np.array([[solt[i,j] for j in range(d)] for i in range(l1)], dtype=int)\n",
    "\n",
    "np.set_printoptions(suppress=True, linewidth=120, precision=6)\n",
    "print(\"W =\\n\", W_val)\n",
    "print(\"b =\", b_val)\n",
    "print(\"v =\", v_val)\n",
    "print(\"p =\\n\", p_val)\n",
    "print(\"q =\\n\", q_val)\n",
    "print(\"z =\\n\", z_val)\n",
    "print(\"s =\\n\", s_val)\n",
    "print(\"t =\\n\", t_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
